{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74f65b9-4561-46fc-b62b-ca7537f0cfb2",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. **Data Splitting**\n",
    "   - Split the dataset into training, testing, and validation sets with a ratio of 60:20:20.\n",
    "\n",
    "2. **Data Filtering**\n",
    "   - Select data samples that have at least 0.1% masks and their corresponding images.\n",
    "\n",
    "3. **Normalization**\n",
    "   - Apply Z-score normalization to the data.\n",
    "\n",
    "4. **Data Transformation**\n",
    "   - Convert 3D data into 2D slices.\n",
    "\n",
    "5. **Cropping**\n",
    "   - Crop the data to a dimension of 192 x 192.\n",
    "\n",
    "6. **Data Format Conversion**\n",
    "   - Convert data from .nii.gz to .npy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f53604-6d15-46f6-9f03-ef951b61a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary module\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172ad46a-1929-42ce-ace1-06b3751bf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "data_folder = \"/path/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc7742e-6bfa-44aa-b65b-c09c3e07c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and Mask files\n",
    "image_files = sorted(glob.glob(os.path.join(data_folder, \"**/*_T1w.nii.gz\"), recursive=True))\n",
    "mask_files = sorted(glob.glob(os.path.join(data_folder, \"**/*_label-L_desc-T1lesion_mask.nii.gz\"), recursive=True))\n",
    "\n",
    "# Spliting train, test and validation sets in the ratio of 60:20:20\n",
    "image_train_files, image_test_val_files = train_test_split(image_files, test_size=0.4, random_state=42)\n",
    "image_test_files, image_val_files = train_test_split(image_test_val_files, test_size=0.5, random_state=42)\n",
    "\n",
    "mask_train_files, mask_test_val_files = train_test_split(mask_files, test_size=0.4, random_state=42)\n",
    "mask_test_files, mask_val_files = train_test_split(mask_test_val_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define the directories to save the train, test, and validation files\n",
    "train_dir = os.path.join(data_folder, 'train')\n",
    "test_dir = os.path.join(data_folder, 'test')\n",
    "val_dir = os.path.join(data_folder, 'val')\n",
    "\n",
    "# Accept atleast 0.1% (threshold)\n",
    "mask_rejection_threshold = 0.001\n",
    "\n",
    "#TRAINING\n",
    "for file_name in image_train_files:\n",
    "    # Load file\n",
    "    file_path = file_name\n",
    "    file_data = nib.load(file_path).get_fdata()\n",
    "\n",
    "    # Load corresponding mask file\n",
    "    mask_file_name = file_name.replace('_T1w.nii.gz', '_label-L_desc-T1lesion_mask.nii.gz')\n",
    "    mask_file_path = os.path.join(os.path.dirname(file_path), mask_file_name)\n",
    "    mask_data = nib.load(mask_file_path).get_fdata()\n",
    "\n",
    "    # Get the shape of the image\n",
    "    x_dim, y_dim, z_dim = file_data.shape\n",
    "    \n",
    "    image_folder = os.path.splitext(file_path)[0] + '_train_image_slices'\n",
    "    os.makedirs(os.path.join(train_dir, image_folder), exist_ok=True)\n",
    "    mask_folder = os.path.splitext(mask_file_path)[0] + '_train_mask_slices'\n",
    "    os.makedirs(os.path.join(train_dir, mask_folder), exist_ok=True)\n",
    "\n",
    "    # Slice along the Z-axis\n",
    "    for i in range(z_dim):\n",
    "        # Extract the 2D slice from the 3D data and mask\n",
    "        slice_data = file_data[:, :, i]\n",
    "        mask_slice_data = mask_data[:, :, i]\n",
    "\n",
    "        # Reject if the mask slice has enough nonzero pixels/lesion \n",
    "        if np.count_nonzero(mask_slice_data) / mask_slice_data.size >= mask_rejection_threshold:\n",
    "            # Crop the image\n",
    "            slice_data_cropped = slice_data[10:190, 40:220]\n",
    "            # Resize the image\n",
    "            slice_data_resized = cv2.resize(slice_data_cropped, (192, 192), interpolation=cv2.INTER_LINEAR)\n",
    "            # Normalize data using Z-score normalization\n",
    "            data_norm = (slice_data_resized - np.mean(slice_data_resized)) / np.std(slice_data_resized, ddof=1)\n",
    "\n",
    "            # Save the image slice as a .npy file in the image folder\n",
    "            slice_filename = os.path.splitext(os.path.basename(file_path))[0] + f'_slice_{i}.npy'\n",
    "            slice_path = os.path.join(train_dir, image_folder, slice_filename)\n",
    "            np.save(slice_path, data_norm)\n",
    "\n",
    "            # Resize the mask\n",
    "            mask_slice_data_cropped = mask_slice_data[10:190, 40:220]\n",
    "            mask_slice_data_resized = cv2.resize(mask_slice_data_cropped, (192, 192), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Save the mask slice as a .npy file in the mask folder\n",
    "            slice_filename = os.path.splitext(os.path.basename(mask_file_path))[0] + f'_slice_{i}.npy'\n",
    "            slice_path = os.path.join(train_dir, mask_folder, slice_filename)\n",
    "            np.save(slice_path, mask_slice_data_resized)\n",
    "\n",
    "###########################################################################################################\n",
    "# TESTING\n",
    "for file_name in image_test_files:\n",
    "    # Load file\n",
    "    file_path = file_name\n",
    "    file_data = nib.load(file_path).get_fdata()\n",
    "\n",
    "    # Load corresponding mask file\n",
    "    mask_file_name = file_name.replace('_T1w.nii.gz', '_label-L_desc-T1lesion_mask.nii.gz')\n",
    "    mask_file_path = os.path.join(os.path.dirname(file_path), mask_file_name)\n",
    "    mask_data = nib.load(mask_file_path).get_fdata()\n",
    "\n",
    "    # Get the shape of the Image\n",
    "    x_dim, y_dim, z_dim = file_data.shape\n",
    "\n",
    "    image_folder = os.path.splitext(file_path)[0] + '_test_image_slices'\n",
    "    os.makedirs(os.path.join(test_dir, image_folder), exist_ok=True)\n",
    "    mask_folder = os.path.splitext(mask_file_path)[0] + '_test_mask_slices'\n",
    "    os.makedirs(os.path.join(test_dir, mask_folder), exist_ok=True)\n",
    "\n",
    "    # Slice along the Z-axis\n",
    "    for i in range(z_dim):\n",
    "        # Extract the 2D slice from the 3D data and mask\n",
    "        slice_data = file_data[:, :, i]\n",
    "        mask_slice_data = mask_data[:, :, i]\n",
    "\n",
    "        # Reject if the mask slice has enough nonzero pixels/'lesions\n",
    "        if np.count_nonzero(mask_slice_data) / mask_slice_data.size >= mask_rejection_threshold:\n",
    "            # Crop the image\n",
    "            slice_data_cropped = slice_data[10:190, 40:220]\n",
    "            # Resize the image\n",
    "            slice_data_resized = cv2.resize(slice_data_cropped, (192, 192), interpolation=cv2.INTER_LINEAR)\n",
    "            # Normalize data using Z-score normalization\n",
    "            data_norm = (slice_data_resized - np.mean(slice_data_resized)) / np.std(slice_data_resized, ddof=1)\n",
    "\n",
    "            # Save the image slice as a .npy file in the image folder\n",
    "            slice_filename = os.path.splitext(os.path.basename(file_path))[0] + f'_slice_{i}.npy'\n",
    "            slice_path = os.path.join(test_dir, image_folder, slice_filename)\n",
    "            np.save(slice_path, data_norm)\n",
    "\n",
    "            # Resize the mask\n",
    "            mask_slice_data_cropped = mask_slice_data[10:190, 40:220]\n",
    "            mask_slice_data_resized = cv2.resize(mask_slice_data_cropped, (192, 192), interpolation=cv2.INTER_NEAREST)\n",
    "            # Save the mask slice as a .npy file in the mask folder\n",
    "            slice_filename = os.path.splitext(os.path.basename(mask_file_path))[0] + f'_slice_{i}.npy'\n",
    "            slice_path = os.path.join(test_dir, mask_folder, slice_filename)\n",
    "            np.save(slice_path, mask_slice_data_resized)\n",
    "##########################################################################################################\n",
    "# VALIDATION\n",
    "for file_name in image_val_files:\n",
    "    # Load file\n",
    "    file_path = file_name\n",
    "    file_data = nib.load(file_path).get_fdata()\n",
    "\n",
    "    # Load corresponding mask file\n",
    "    mask_file_name = file_name.replace('_T1w.nii.gz', '_label-L_desc-T1lesion_mask.nii.gz')\n",
    "    mask_file_path = os.path.join(os.path.dirname(file_path), mask_file_name)\n",
    "    mask_data = nib.load(mask_file_path).get_fdata()\n",
    "\n",
    "    # Get the shape of the Image\n",
    "    x_dim, y_dim, z_dim = file_data.shape\n",
    "\n",
    "    image_folder = os.path.splitext(file_path)[0] + '_val_image_slices'\n",
    "    os.makedirs(os.path.join(val_dir, image_folder), exist_ok=True)\n",
    "    mask_folder = os.path.splitext(mask_file_path)[0] + '_val_mask_slices'\n",
    "    os.makedirs(os.path.join(val_dir, mask_folder), exist_ok=True)\n",
    "\n",
    "    # Slice along the Z-axis\n",
    "    for i in range(z_dim):\n",
    "        # Extract the 2D slice from the 3D data and mask\n",
    "        slice_data = file_data[:, :, i]\n",
    "        mask_slice_data = mask_data[:, :, i]\n",
    "\n",
    "        # Reject if the mask slice has enough nonzero pixels/lesions\n",
    "        if np.count_nonzero(mask_slice_data) / mask_slice_data.size >= mask_rejection_threshold:\n",
    "            # Crop the image\n",
    "            slice_data_cropped = slice_data[10:190, 40:220]\n",
    "            # Resize the image\n",
    "            slice_data_resized = cv2.resize(slice_data_cropped, (192, 192), interpolation=cv2.INTER_LINEAR)\n",
    "            # Normalize data using Z-score normalization\n",
    "            data_norm = (slice_data_resized - np.mean(slice_data_resized)) / np.std(slice_data_resized, ddof=1)\n",
    "\n",
    "            # Save the image slice as a .npy file in the image folder\n",
    "            slice_filename = os.path.splitext(os.path.basename(file_path))[0] + f'_slice_{i}.npy'\n",
    "            slice_path = os.path.join(val_dir, image_folder, slice_filename)\n",
    "            np.save(slice_path, data_norm)\n",
    "\n",
    "            # Resize the mask\n",
    "            mask_slice_data_cropped = mask_slice_data[10:190, 40:220]\n",
    "            mask_slice_data_resized = cv2.resize(mask_slice_data_cropped, (192, 192), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Save the mask slice as a .npy file in the mask folder\n",
    "            slice_filename = os.path.splitext(os.path.basename(mask_file_path))[0] + f'_slice_{i}.npy'\n",
    "            slice_path = os.path.join(val_dir, mask_folder, slice_filename)\n",
    "            np.save(slice_path, mask_slice_data_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a315492-cdb1-4c94-bc75-1b3eda28cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image .npy files: 15394\n",
      "Mask .npy files: 15394\n",
      "Image .npy files: 4666\n",
      "Mask .npy files: 4666\n",
      "Image .npy files: 5452\n",
      "Mask .npy files: 5452\n"
     ]
    }
   ],
   "source": [
    "# Get the .npy folder\n",
    "image_npy_files_train = sorted(glob.glob(os.path.join(data_folder, \"**/*_train_image_slices/*.npy\"), recursive=True))\n",
    "mask_npy_files_train = sorted(glob.glob(os.path.join(data_folder, \"**/*_train_mask_slices/*.npy\"), recursive=True))\n",
    "image_npy_files_test = sorted(glob.glob(os.path.join(data_folder, \"**/*_test_image_slices/*.npy\"), recursive=True))\n",
    "mask_npy_files_test = sorted(glob.glob(os.path.join(data_folder, \"**/*_test_mask_slices/*.npy\"), recursive=True))\n",
    "image_npy_files_val = sorted(glob.glob(os.path.join(data_folder, \"**/*_val_image_slices/*.npy\"), recursive=True))\n",
    "mask_npy_files_val = sorted(glob.glob(os.path.join(data_folder, \"**/*_val_mask_slices/*.npy\"), recursive=True))\n",
    "\n",
    "print(\"Image .npy files:\", len(image_npy_files_train))\n",
    "print(\"Mask .npy files:\", len(mask_npy_files_train))\n",
    "\n",
    "print(\"Image .npy files:\", len(image_npy_files_test))\n",
    "print(\"Mask .npy files:\", len(mask_npy_files_test))\n",
    "\n",
    "print(\"Image .npy files:\", len(image_npy_files_val))\n",
    "print(\"Mask .npy files:\", len(mask_npy_files_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215b8594-2809-440b-9ea0-f209ec68f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_image_folder = os.path.join(data_folder, \"train\", \"images\")\n",
    "train_mask_folder = os.path.join(data_folder, \"train\", \"masks\")\n",
    "\n",
    "if not os.path.exists(train_image_folder):\n",
    "    os.makedirs(train_image_folder)\n",
    "if not os.path.exists(train_mask_folder):\n",
    "    os.makedirs(train_mask_folder)\n",
    "\n",
    "# Save image and mask files to train/images and train/masks\n",
    "for i in range(len(image_npy_files_train)):\n",
    "    image_path = image_npy_files_train[i]\n",
    "    mask_path = mask_npy_files_train[i]\n",
    "    file_name = os.path.basename(image_path)\n",
    "    shutil.copy(image_path, os.path.join(train_image_folder, file_name))\n",
    "    shutil.copy(mask_path, os.path.join(train_mask_folder, file_name))\n",
    "\n",
    "# Test\n",
    "test_image_folder = os.path.join(data_folder, \"test\", \"images\")\n",
    "test_mask_folder = os.path.join(data_folder, \"test\", \"masks\")\n",
    "\n",
    "if not os.path.exists(test_image_folder):\n",
    "    os.makedirs(test_image_folder)\n",
    "if not os.path.exists(test_mask_folder):\n",
    "    os.makedirs(test_mask_folder)\n",
    "\n",
    "# Save image and mask files to test/images and test/masks\n",
    "for i in range(len(image_npy_files_test)):\n",
    "    image_path = image_npy_files_test[i]\n",
    "    mask_path = mask_npy_files_test[i]\n",
    "    file_name = os.path.basename(image_path)\n",
    "    shutil.copy(image_path, os.path.join(test_image_folder, file_name))\n",
    "    shutil.copy(mask_path, os.path.join(test_mask_folder, file_name))\n",
    "\n",
    "# Validation \n",
    "val_image_folder = os.path.join(data_folder, \"val\", \"images\")\n",
    "val_mask_folder = os.path.join(data_folder, \"val\", \"masks\")\n",
    "\n",
    "if not os.path.exists(val_image_folder):\n",
    "    os.makedirs(val_image_folder)\n",
    "if not os.path.exists(val_mask_folder):\n",
    "    os.makedirs(val_mask_folder)\n",
    "\n",
    "# Save image and mask files to val/images and val/masks\n",
    "for i in range(len(image_npy_files_val)):\n",
    "    image_path = image_npy_files_val[i]\n",
    "    mask_path = mask_npy_files_val[i]\n",
    "    file_name = os.path.basename(image_path)\n",
    "    shutil.copy(image_path, os.path.join(val_image_folder, file_name))\n",
    "    shutil.copy(mask_path, os.path.join(val_mask_folder, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09010bf3-a50f-4610-a6c7-bec83aac4ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train/images: 15394\n",
      "Number of masks in train/masks: 15394\n",
      "Number of images in test/images: 4666\n",
      "Number of masks in test/masks: 4666\n",
      "Number of images in val/images: 5452\n",
      "Number of masks in val/masks: 5452\n"
     ]
    }
   ],
   "source": [
    "# Train folder\n",
    "train_image_folder = \"/path/train/images\"\n",
    "train_mask_folder = \"/path/train/masks\"\n",
    "\n",
    "num_images = len(os.listdir(train_image_folder))\n",
    "num_masks = len(os.listdir(train_mask_folder))\n",
    "\n",
    "print(\"Number of images in train/images:\", num_images)\n",
    "print(\"Number of masks in train/masks:\", num_masks)\n",
    "\n",
    "# Test Folder\n",
    "test_image_folder = \"/path/test/images\"\n",
    "test_mask_folder = \"/path/test/masks\"\n",
    "\n",
    "num_images = len(os.listdir(test_image_folder))\n",
    "num_masks = len(os.listdir(test_mask_folder))\n",
    "\n",
    "print(\"Number of images in test/images:\", num_images)\n",
    "print(\"Number of masks in test/masks:\", num_masks)\n",
    "\n",
    "# Validation Folder\n",
    "val_image_folder = \"/path/val/images\"\n",
    "val_mask_folder = \"/path/val/masks\"\n",
    "\n",
    "num_images = len(os.listdir(val_image_folder))\n",
    "num_masks = len(os.listdir(val_mask_folder))\n",
    "\n",
    "print(\"Number of images in val/images:\", num_images)\n",
    "print(\"Number of masks in val/masks:\", num_masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
