{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc47abc-de54-4393-9d63-869b3d09cd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a81260-4bc0-4a4f-a969-eda3b65bf4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cef494-e9df-492a-81cc-131b294f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################   DATALOADER    ###########################################\n",
    "class MedicalImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        msk_name = self.mask_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        msk_path = os.path.join(self.mask_dir, msk_name)\n",
    "        img = np.load(img_path)\n",
    "        msk = np.load(msk_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        msk = np.expand_dims(msk, axis=0)\n",
    "        subject_id = img_name.split('_')[0]\n",
    "        return {'image': torch.from_numpy(img), 'mask': torch.from_numpy(msk)}\n",
    "\n",
    "test_image_folder = \"/ssd_scratch/ATLAS/Training/test/images\"\n",
    "test_mask_folder = \"/ssd_scratch/ATLAS/Training/test/masks\"\n",
    "test_dataset = MedicalImageSegmentationDataset(test_image_folder, test_mask_folder)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876554d4-1878-4282-939d-ce2405533027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResUNet(\n",
       "    (inc): ResidualBlock(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (dropout1): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ResidualBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ResidualBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ResidualBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ResidualBlock(\n",
       "          (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up(\n",
       "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ResidualBlock(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ResidualBlock(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv(\n",
       "      (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################     MODEL 2D Residual U-NET         ###########################\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Double convolutional block with residual connection\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = ResidualBlock(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = ResidualBlock(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=1, bilinear=False):\n",
    "        super(ResUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.inc = (ResidualBlock(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "model = ResUNet(n_channels=1, n_classes=1)\n",
    "model = DataParallel(model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('/home/prantik.deb/notebooks/2D_models_demo/best_model_resunet2D.pth', map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97617b5a-9180-4f9f-845e-536eed4d99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################         LOSS FUNCTION      ########################################\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, squared_denom=False):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = sys.float_info.epsilon\n",
    "        self.squared_denom = squared_denom\n",
    "    def forward(self, x, target):\n",
    "        x = x.view(-1)\n",
    "        target = target.view(-1)\n",
    "        intersection = (x * target).sum()\n",
    "        numer = 2. * intersection + self.smooth\n",
    "        factor = 2 if self.squared_denom else 1\n",
    "        denom = x.pow(factor).sum() + target.pow(factor).sum() + self.smooth\n",
    "        dice_index = numer / denom\n",
    "        return 1 - dice_index\n",
    "class BCEWithLogitsAndDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.1, smooth=1.):\n",
    "        super(BCEWithLogitsAndDiceLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.smooth = smooth\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = self.bce_loss(inputs, targets)\n",
    "        dice_loss = self.dice_loss(torch.sigmoid(inputs), targets)\n",
    "        loss = self.bce_weight * bce_loss + (1. - self.bce_weight) * dice_loss\n",
    "        return loss.mean()\n",
    "criterion = BCEWithLogitsAndDiceLoss(bce_weight=0.1)\n",
    "\n",
    "def dice_coefficient(inputs, labels, smooth=1):\n",
    "    inputs = inputs.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    intersection = (inputs * labels).sum()\n",
    "    union = inputs.sum() + labels.sum()\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "# IOU\n",
    "def IoU(output, labels):\n",
    "    smooth = 1.\n",
    "    intersection = torch.logical_and(output, labels).sum()\n",
    "    union = torch.logical_or(output, labels).sum()\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d6f15-7961-4fcf-bc52-1d164c5d78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Results\n",
    "ep3 = []\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_dice = 0.0\n",
    "test_iou = 0.0\n",
    "num_slices = 0\n",
    "test_precision = 0.0\n",
    "test_recall = 0.0\n",
    "if not os.path.exists('/ssd_scratch/ATLAS_2/results_2d/results_resunet'):\n",
    "    os.makedirs('/ssd_scratch/ATLAS_2/results_2d/results_resunet')\n",
    "with torch.no_grad(): \n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data['image'], data['mask']\n",
    "        inputs = inputs.to('cuda').float()\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()        \n",
    "        batch_dice = []\n",
    "        batch_iou = []\n",
    "        batch_precision = []\n",
    "        batch_recall = []\n",
    "        for j in range(outputs.shape[0]):\n",
    "            dice = dice_coefficient(torch.sigmoid(outputs[j]), labels[j]).item()\n",
    "            iou = IoU(outputs[j] > 0.5, labels[j] > 0.5).item()            \n",
    "            true_positives = torch.sum((outputs[j] > 0.5) & (labels[j] > 0.5)).item()\n",
    "            false_positives = torch.sum((outputs[j] > 0.5) & (labels[j] <= 0.5)).item()\n",
    "            false_negatives = torch.sum((outputs[j] <= 0.5) & (labels[j] > 0.5)).item()            \n",
    "            precision = true_positives / (true_positives + false_positives + 1e-6)\n",
    "            recall = true_positives / (true_positives + false_negatives + 1e-6)            \n",
    "            batch_dice.append(dice)\n",
    "            batch_iou.append(iou)\n",
    "            batch_precision.append(precision)\n",
    "            batch_recall.append(recall)            \n",
    "        test_dice += np.mean(batch_dice)\n",
    "        test_iou += np.mean(batch_iou)\n",
    "        test_precision += np.mean(batch_precision)\n",
    "        test_recall += np.mean(batch_recall)       \n",
    "        # Save the image, ground truth mask, and predicted mask together for comparison\n",
    "        for j in range(len(inputs)):\n",
    "            image = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "            ground_truth_mask = labels[j].cpu().numpy().squeeze()  \n",
    "            predicted_mask = torch.sigmoid(outputs[j]).cpu().numpy() > 0.5\n",
    "            predicted_mask = predicted_mask.squeeze() \n",
    "            plt.figure()\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title('Image')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(ground_truth_mask, cmap='gray')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted_mask, cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('/ssd_scratch/ATLAS_2/results_2d/results_resunet/result_{}_{}.png'.format(i, j), dpi=100)\n",
    "            plt.close()            \n",
    "        #After processing all the batches, the average metrics per slice are computed by dividing the \n",
    "        #accumulated metrics (test_loss, test_dice, test_iou, test_precision, test_recall) by the total \n",
    "        #number of slices (num_slices)\n",
    "    # Calculate average metrics for the test dataset\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_dice = test_dice / len(test_dataloader)\n",
    "    avg_test_iou = test_iou / len(test_dataloader)\n",
    "    avg_test_precision = test_precision / len(test_dataloader)\n",
    "    avg_test_recall = test_recall / len(test_dataloader)\n",
    "    # Append epoch metrics to the list\n",
    "    ep3.append([avg_test_loss, avg_test_dice, avg_test_iou, avg_test_precision, avg_test_recall])\n",
    "    # Print the average metrics\n",
    "    print('Average Test Dice: {:.4f}'.format(avg_test_dice))\n",
    "    print('Average Test IoU: {:.4f}'.format(avg_test_iou))\n",
    "    print('Average Test Precision: {:.4f}'.format(avg_test_precision))\n",
    "    print('Average Test Recall: {:.4f}'.format(avg_test_recall))\n",
    "\n",
    "ep_df = pd.DataFrame(np.array(ep3), columns=['Loss', 'Dice', 'IoU', 'Precision', 'Recall'])\n",
    "ep_df.to_csv('metrics_test_resunet.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
