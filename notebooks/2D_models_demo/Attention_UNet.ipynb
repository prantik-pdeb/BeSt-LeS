{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc47abc-de54-4393-9d63-869b3d09cd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a81260-4bc0-4a4f-a969-eda3b65bf4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cef494-e9df-492a-81cc-131b294f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################   DATALOADER    ###########################################\n",
    "class MedicalImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        msk_name = self.mask_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        msk_path = os.path.join(self.mask_dir, msk_name)\n",
    "        img = np.load(img_path)\n",
    "        msk = np.load(msk_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        msk = np.expand_dims(msk, axis=0)\n",
    "        subject_id = img_name.split('_')[0]\n",
    "        return {'image': torch.from_numpy(img), 'mask': torch.from_numpy(msk)}\n",
    "\n",
    "test_image_folder = \"/ssd_scratch/ATLAS/Training/test/images\"\n",
    "test_mask_folder = \"/ssd_scratch/ATLAS/Training/test/masks\"\n",
    "test_dataset = MedicalImageSegmentationDataset(test_image_folder, test_mask_folder)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876554d4-1878-4282-939d-ce2405533027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AttU_Net(\n",
       "    (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv1): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Conv2): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Conv3): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Conv4): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Conv5): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Up5): up_conv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att5): Attention_block(\n",
       "      (W_g): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (Up_conv5): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Up4): up_conv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att4): Attention_block(\n",
       "      (W_g): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (Up_conv4): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Up3): up_conv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att3): Attention_block(\n",
       "      (W_g): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (Up_conv3): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Up2): up_conv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att2): Attention_block(\n",
       "      (W_g): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (Up_conv2): conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################     MODEL 2D Attention U-NET         ###########################\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2), \n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),  \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(Attention_block, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "class AttU_Net(nn.Module):\n",
    "    def __init__(self, img_ch=1, output_ch=1, num_classes=1):\n",
    "        super(AttU_Net, self).__init__()\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64, ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128, ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256, ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512, ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512, F_l=512, F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256, F_l=256, F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128, F_l=128, F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64, F_l=64, F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "        self.final_conv = nn.Conv2d(output_ch, num_classes, kernel_size=1, stride=1, padding=0)\n",
    "    def forward(self, x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "        \n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5, x=x4)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4, x=x3)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3, x=x2)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2, x=x1)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "        return d1\n",
    "model = AttU_Net(img_ch=1, output_ch=1, num_classes=1)\n",
    "model = DataParallel(model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('/home/prantik.deb/notebooks/2D_models_demo/best_model_att_unet2D.pth', map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97617b5a-9180-4f9f-845e-536eed4d99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################         LOSS FUNCTION      ########################################\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, squared_denom=False):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = sys.float_info.epsilon\n",
    "        self.squared_denom = squared_denom\n",
    "    def forward(self, x, target):\n",
    "        x = x.view(-1)\n",
    "        target = target.view(-1)\n",
    "        intersection = (x * target).sum()\n",
    "        numer = 2. * intersection + self.smooth\n",
    "        factor = 2 if self.squared_denom else 1\n",
    "        denom = x.pow(factor).sum() + target.pow(factor).sum() + self.smooth\n",
    "        dice_index = numer / denom\n",
    "        return 1 - dice_index\n",
    "class BCEWithLogitsAndDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.1, smooth=1.):\n",
    "        super(BCEWithLogitsAndDiceLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.smooth = smooth\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = self.bce_loss(inputs, targets)\n",
    "        dice_loss = self.dice_loss(torch.sigmoid(inputs), targets)\n",
    "        loss = self.bce_weight * bce_loss + (1. - self.bce_weight) * dice_loss\n",
    "        return loss.mean()\n",
    "criterion = BCEWithLogitsAndDiceLoss(bce_weight=0.1)\n",
    "\n",
    "def dice_coefficient(inputs, labels, smooth=1):\n",
    "    inputs = inputs.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    intersection = (inputs * labels).sum()\n",
    "    union = inputs.sum() + labels.sum()\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "# IOU\n",
    "def IoU(output, labels):\n",
    "    smooth = 1.\n",
    "    intersection = torch.logical_and(output, labels).sum()\n",
    "    union = torch.logical_or(output, labels).sum()\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6d6f15-7961-4fcf-bc52-1d164c5d78cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Dice: 0.4680\n",
      "Average Test IoU: 0.3784\n",
      "Average Test Precision: 0.6117\n",
      "Average Test Recall: 0.4291\n"
     ]
    }
   ],
   "source": [
    "# Saving Results\n",
    "ep3 = []\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_dice = 0.0\n",
    "test_iou = 0.0\n",
    "num_slices = 0\n",
    "test_precision = 0.0\n",
    "test_recall = 0.0\n",
    "if not os.path.exists('/ssd_scratch/ATLAS_2/results_2d/results_attunet'):\n",
    "    os.makedirs('/ssd_scratch/ATLAS_2/results_2d/results_attunet')\n",
    "with torch.no_grad(): \n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data['image'], data['mask']\n",
    "        inputs = inputs.to('cuda').float()\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()        \n",
    "        batch_dice = []\n",
    "        batch_iou = []\n",
    "        batch_precision = []\n",
    "        batch_recall = []\n",
    "        for j in range(outputs.shape[0]):\n",
    "            dice = dice_coefficient(torch.sigmoid(outputs[j]), labels[j]).item()\n",
    "            iou = IoU(outputs[j] > 0.5, labels[j] > 0.5).item()            \n",
    "            true_positives = torch.sum((outputs[j] > 0.5) & (labels[j] > 0.5)).item()\n",
    "            false_positives = torch.sum((outputs[j] > 0.5) & (labels[j] <= 0.5)).item()\n",
    "            false_negatives = torch.sum((outputs[j] <= 0.5) & (labels[j] > 0.5)).item()            \n",
    "            precision = true_positives / (true_positives + false_positives + 1e-6)\n",
    "            recall = true_positives / (true_positives + false_negatives + 1e-6)            \n",
    "            batch_dice.append(dice)\n",
    "            batch_iou.append(iou)\n",
    "            batch_precision.append(precision)\n",
    "            batch_recall.append(recall)            \n",
    "        test_dice += np.mean(batch_dice)\n",
    "        test_iou += np.mean(batch_iou)\n",
    "        test_precision += np.mean(batch_precision)\n",
    "        test_recall += np.mean(batch_recall)       \n",
    "        # Save the image, ground truth mask, and predicted mask together for comparison\n",
    "        for j in range(len(inputs)):\n",
    "            image = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "            ground_truth_mask = labels[j].cpu().numpy().squeeze()  \n",
    "            predicted_mask = torch.sigmoid(outputs[j]).cpu().numpy() > 0.5\n",
    "            predicted_mask = predicted_mask.squeeze() \n",
    "            plt.figure()\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title('Image')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(ground_truth_mask, cmap='gray')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted_mask, cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('/ssd_scratch/ATLAS_2/results_2d/results_attunet/result_{}_{}.png'.format(i, j), dpi=100)\n",
    "            plt.close()            \n",
    "        #After processing all the batches, the average metrics per slice are computed by dividing the \n",
    "        #accumulated metrics (test_loss, test_dice, test_iou, test_precision, test_recall) by the total \n",
    "        #number of slices (num_slices)\n",
    "    # Calculate average metrics for the test dataset\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_dice = test_dice / len(test_dataloader)\n",
    "    avg_test_iou = test_iou / len(test_dataloader)\n",
    "    avg_test_precision = test_precision / len(test_dataloader)\n",
    "    avg_test_recall = test_recall / len(test_dataloader)\n",
    "    # Append epoch metrics to the list\n",
    "    ep3.append([avg_test_loss, avg_test_dice, avg_test_iou, avg_test_precision, avg_test_recall])\n",
    "    # Print the average metrics\n",
    "    print('Average Test Dice: {:.4f}'.format(avg_test_dice))\n",
    "    print('Average Test IoU: {:.4f}'.format(avg_test_iou))\n",
    "    print('Average Test Precision: {:.4f}'.format(avg_test_precision))\n",
    "    print('Average Test Recall: {:.4f}'.format(avg_test_recall))\n",
    "\n",
    "ep_df = pd.DataFrame(np.array(ep3), columns=['Loss', 'Dice', 'IoU', 'Precision', 'Recall'])\n",
    "ep_df.to_csv('metrics_test_attunet.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbf6bd-ee2b-416c-85ac-b29a1cc5f989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
