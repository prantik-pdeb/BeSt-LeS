{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc47abc-de54-4393-9d63-869b3d09cd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a81260-4bc0-4a4f-a969-eda3b65bf4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cef494-e9df-492a-81cc-131b294f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################   DATALOADER    ###########################################\n",
    "class MedicalImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        msk_name = self.mask_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        msk_path = os.path.join(self.mask_dir, msk_name)\n",
    "        img = np.load(img_path)\n",
    "        msk = np.load(msk_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        msk = np.expand_dims(msk, axis=0)\n",
    "        subject_id = img_name.split('_')[0]\n",
    "        return {'image': torch.from_numpy(img), 'mask': torch.from_numpy(msk)}\n",
    "\n",
    "test_image_folder = \"/ssd_scratch/ATLAS/Training/test/images\"\n",
    "test_mask_folder = \"/ssd_scratch/ATLAS/Training/test/masks\"\n",
    "test_dataset = MedicalImageSegmentationDataset(test_image_folder, test_mask_folder)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876554d4-1878-4282-939d-ce2405533027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): UNet_Attention_Transformer_Multiscale(\n",
       "    (inc): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up(\n",
       "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up(\n",
       "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up(\n",
       "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up(\n",
       "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (conv): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv(\n",
       "      (conv): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (pos): PositionEmbeddingLearned(\n",
       "      (row_embed): Embedding(32, 256)\n",
       "      (col_embed): Embedding(32, 256)\n",
       "    )\n",
       "    (pam): PAM_Module(\n",
       "      (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (sdpa): ScaledDotProductAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fuse1): MultiConv(\n",
       "      (fuse_attn): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): Softmax2d()\n",
       "      )\n",
       "    )\n",
       "    (fuse2): MultiConv(\n",
       "      (fuse_attn): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): Softmax2d()\n",
       "      )\n",
       "    )\n",
       "    (fuse3): MultiConv(\n",
       "      (fuse_attn): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): Softmax2d()\n",
       "      )\n",
       "    )\n",
       "    (fuse4): MultiConv(\n",
       "      (fuse_attn): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=1)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=1)\n",
       "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): Softmax2d()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D TransAttUnet  Architecture\n",
    "'''Original Code: https://github.com/YishuLiu/TransAttUnet/blob/main/model/TransAttUnet.py\n",
    "'''\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class MultiConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, attn=True):\n",
    "        super(MultiConv, self).__init__()\n",
    "\n",
    "        self.fuse_attn = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.Softmax2d() if attn else nn.PReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fuse_attn(x)\n",
    "\n",
    "class PAM_Module(nn.Module):\n",
    "    \"\"\"空间注意力模块\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(PAM_Module, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        m_batchsize, C, height, width = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width * height)\n",
    "\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width * height)\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(m_batchsize, C, height, width)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "class PositionEmbeddingLearned(nn.Module):\n",
    "    \"\"\"\n",
    "    可学习的位置编码\n",
    "    \"\"\"\n",
    "    def __init__(self, num_pos_feats=256, len_embedding=32):\n",
    "        super().__init__()\n",
    "        self.row_embed = nn.Embedding(len_embedding, num_pos_feats)\n",
    "        self.col_embed = nn.Embedding(len_embedding, num_pos_feats)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.row_embed.weight)\n",
    "        nn.init.uniform_(self.col_embed.weight)\n",
    "\n",
    "    def forward(self, tensor_list):\n",
    "        x = tensor_list\n",
    "        h, w = x.shape[-2:]\n",
    "        i = torch.arange(w, device=x.device)\n",
    "        j = torch.arange(h, device=x.device)\n",
    "\n",
    "        x_emb = self.col_embed(i)\n",
    "        y_emb = self.row_embed(j)\n",
    "\n",
    "        pos = torch.cat([\n",
    "            x_emb.unsqueeze(0).repeat(h, 1, 1),\n",
    "            y_emb.unsqueeze(1).repeat(1, w, 1),\n",
    "        ], dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(x.shape[0], 1, 1, 1)\n",
    "\n",
    "        return pos\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    '''自注意力模块'''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature ** 0.5\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        m_batchsize, d, height, width = x.size()\n",
    "        q = x.view(m_batchsize, d, -1)\n",
    "        k = x.view(m_batchsize, d, -1)\n",
    "        k = k.permute(0, 2, 1)\n",
    "        v = x.view(m_batchsize, d, -1)\n",
    "\n",
    "        attn = torch.matmul(q / self.temperature, k)\n",
    "\n",
    "        if mask is not None:\n",
    "            # 给需要mask的地方设置一个负无穷\n",
    "            attn = attn.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
    "        output = torch.matmul(attn, v)\n",
    "        output = output.view(m_batchsize, d, height, width)\n",
    "        return output\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet_Attention_Transformer_Multiscale(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=1, bilinear=True):\n",
    "        super(UNet_Attention_Transformer_Multiscale, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(1024, 256 // factor, bilinear)\n",
    "        self.up3 = Up(512, 128 // factor, bilinear)\n",
    "        self.up4 = Up(256, 64, bilinear)\n",
    "        self.outc = OutConv(128, n_classes)\n",
    "\n",
    "        '''位置编码'''\n",
    "        self.pos = PositionEmbeddingLearned(512 // factor)\n",
    "\n",
    "        '''空间注意力机制'''\n",
    "        self.pam = PAM_Module(512)\n",
    "\n",
    "        '''自注意力机制'''\n",
    "        self.sdpa = ScaledDotProductAttention(512)\n",
    "\n",
    "        '''残差多尺度连接'''\n",
    "        self.fuse1 = MultiConv(768, 256)\n",
    "        self.fuse2 = MultiConv(384, 128)\n",
    "        self.fuse3 = MultiConv(192, 64)\n",
    "        self.fuse4 = MultiConv(128, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        '''Setting 1'''\n",
    "        x5_pam = self.pam(x5)\n",
    "        '''Setting 2'''\n",
    "        x5_pos = self.pos(x5)\n",
    "        x5 = x5 + x5_pos\n",
    "        x5_sdpa = self.sdpa(x5)\n",
    "        x6 = self.up1(x5, x4)\n",
    "        x5_scale = F.interpolate(x5, size=x6.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x6_cat = torch.cat((x5_scale, x6), 1)\n",
    "        x7 = self.up2(x6_cat, x3)\n",
    "        x6_scale = F.interpolate(x6, size=x7.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x7_cat = torch.cat((x6_scale, x7), 1)\n",
    "        x8 = self.up3(x7_cat, x2)\n",
    "        x7_scale = F.interpolate(x7, size=x8.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x8_cat = torch.cat((x7_scale, x8), 1)\n",
    "        x9 = self.up4(x8_cat, x1)\n",
    "        x8_scale = F.interpolate(x8, size=x9.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x9 = torch.cat((x8_scale, x9), 1)\n",
    "        logits = self.outc(x9)\n",
    "        return logits\n",
    "        \n",
    "model = UNet_Attention_Transformer_Multiscale(n_channels=1, n_classes=1)\n",
    "model = DataParallel(model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('/home/prantik.deb/notebooks/2D_models_demo/best_model_transatt_unet2D.pth', map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97617b5a-9180-4f9f-845e-536eed4d99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################         LOSS FUNCTION      ########################################\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, squared_denom=False):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = sys.float_info.epsilon\n",
    "        self.squared_denom = squared_denom\n",
    "    def forward(self, x, target):\n",
    "        x = x.view(-1)\n",
    "        target = target.view(-1)\n",
    "        intersection = (x * target).sum()\n",
    "        numer = 2. * intersection + self.smooth\n",
    "        factor = 2 if self.squared_denom else 1\n",
    "        denom = x.pow(factor).sum() + target.pow(factor).sum() + self.smooth\n",
    "        dice_index = numer / denom\n",
    "        return 1 - dice_index\n",
    "class BCEWithLogitsAndDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.1, smooth=1.):\n",
    "        super(BCEWithLogitsAndDiceLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.smooth = smooth\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = self.bce_loss(inputs, targets)\n",
    "        dice_loss = self.dice_loss(torch.sigmoid(inputs), targets)\n",
    "        loss = self.bce_weight * bce_loss + (1. - self.bce_weight) * dice_loss\n",
    "        return loss.mean()\n",
    "criterion = BCEWithLogitsAndDiceLoss(bce_weight=0.1)\n",
    "\n",
    "def dice_coefficient(inputs, labels, smooth=1):\n",
    "    inputs = inputs.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    intersection = (inputs * labels).sum()\n",
    "    union = inputs.sum() + labels.sum()\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "# IOU\n",
    "def IoU(output, labels):\n",
    "    smooth = 1.\n",
    "    intersection = torch.logical_and(output, labels).sum()\n",
    "    union = torch.logical_or(output, labels).sum()\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6d6f15-7961-4fcf-bc52-1d164c5d78cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Dice: 0.5794\n",
      "Average Test IoU: 0.4719\n",
      "Average Test Precision: 0.6564\n",
      "Average Test Recall: 0.5827\n"
     ]
    }
   ],
   "source": [
    "# Saving Results\n",
    "ep3 = []\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_dice = 0.0\n",
    "test_iou = 0.0\n",
    "num_slices = 0\n",
    "test_precision = 0.0\n",
    "test_recall = 0.0\n",
    "if not os.path.exists('/ssd_scratch/ATLAS_2/results_2d/results_att_trans_unet'):\n",
    "    os.makedirs('/ssd_scratch/ATLAS_2/results_2d/results_att_trans_unet')\n",
    "with torch.no_grad(): \n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data['image'], data['mask']\n",
    "        inputs = inputs.to('cuda').float()\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()        \n",
    "        batch_dice = []\n",
    "        batch_iou = []\n",
    "        batch_precision = []\n",
    "        batch_recall = []\n",
    "        for j in range(outputs.shape[0]):\n",
    "            dice = dice_coefficient(torch.sigmoid(outputs[j]), labels[j]).item()\n",
    "            iou = IoU(outputs[j] > 0.5, labels[j] > 0.5).item()            \n",
    "            true_positives = torch.sum((outputs[j] > 0.5) & (labels[j] > 0.5)).item()\n",
    "            false_positives = torch.sum((outputs[j] > 0.5) & (labels[j] <= 0.5)).item()\n",
    "            false_negatives = torch.sum((outputs[j] <= 0.5) & (labels[j] > 0.5)).item()            \n",
    "            precision = true_positives / (true_positives + false_positives + 1e-6)\n",
    "            recall = true_positives / (true_positives + false_negatives + 1e-6)            \n",
    "            batch_dice.append(dice)\n",
    "            batch_iou.append(iou)\n",
    "            batch_precision.append(precision)\n",
    "            batch_recall.append(recall)            \n",
    "        test_dice += np.mean(batch_dice)\n",
    "        test_iou += np.mean(batch_iou)\n",
    "        test_precision += np.mean(batch_precision)\n",
    "        test_recall += np.mean(batch_recall)       \n",
    "        # Save the image, ground truth mask, and predicted mask together for comparison\n",
    "        for j in range(len(inputs)):\n",
    "            image = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "            ground_truth_mask = labels[j].cpu().numpy().squeeze()  \n",
    "            predicted_mask = torch.sigmoid(outputs[j]).cpu().numpy() > 0.5\n",
    "            predicted_mask = predicted_mask.squeeze() \n",
    "            plt.figure()\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title('Image')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(ground_truth_mask, cmap='gray')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted_mask, cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('/ssd_scratch/ATLAS_2/results_2d/results_att_trans_unet/result_{}_{}.png'.format(i, j), dpi=100)\n",
    "            plt.close()            \n",
    "        #After processing all the batches, the average metrics per slice are computed by dividing the \n",
    "        #accumulated metrics (test_loss, test_dice, test_iou, test_precision, test_recall) by the total \n",
    "        #number of slices (num_slices)\n",
    "    # Calculate average metrics for the test dataset\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_dice = test_dice / len(test_dataloader)\n",
    "    avg_test_iou = test_iou / len(test_dataloader)\n",
    "    avg_test_precision = test_precision / len(test_dataloader)\n",
    "    avg_test_recall = test_recall / len(test_dataloader)\n",
    "    # Append epoch metrics to the list\n",
    "    ep3.append([avg_test_loss, avg_test_dice, avg_test_iou, avg_test_precision, avg_test_recall])\n",
    "    # Print the average metrics\n",
    "    print('Average Test Dice: {:.4f}'.format(avg_test_dice))\n",
    "    print('Average Test IoU: {:.4f}'.format(avg_test_iou))\n",
    "    print('Average Test Precision: {:.4f}'.format(avg_test_precision))\n",
    "    print('Average Test Recall: {:.4f}'.format(avg_test_recall))\n",
    "\n",
    "ep_df = pd.DataFrame(np.array(ep3), columns=['Loss', 'Dice', 'IoU', 'Precision', 'Recall'])\n",
    "ep_df.to_csv('metrics_test_att_trans_unet.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbf6bd-ee2b-416c-85ac-b29a1cc5f989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
